{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and deploy on Google Cloud Platform (GCP)\n",
    "\n",
    "This notebook introduces you to using Kubeflow Fairing to train and deploy a model to Kubeflow on Google Kubernetes Engine (GKE), and Google Cloud ML Engine. This notebook demonstrate how to:\n",
    " \n",
    "* Train an XGBoost model in a local notebook,\n",
    "* Use Kubeflow Fairing to train an XGBoost model remotely on Kubeflow,\n",
    "* Use Kubeflow Fairing to train an XGBoost model remotely on Cloud ML Engine,\n",
    "* Use Kubeflow Fairing to deploy a trained model to Kubeflow, and\n",
    "* Call the deployed endpoint for predictions.\n",
    "\n",
    "To learn more about how to run this notebook locally, see the guide to [training and deploying on GCP from a local notebook][gcp-local-notebook].\n",
    "\n",
    "[gcp-local-notebook]: https://kubeflow.org/docs/fairing/gcp-local-notebook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding /home/jovyan/git_kubeflow-fairing to path\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import importlib\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(message)s')\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "fairing_code = os.path.join(Path.home(), \"git_kubeflow-fairing\")\n",
    "\n",
    "if os.path.exists(fairing_code):    \n",
    "    logging.info(\"Adding %s to path\", fairing_code)\n",
    "    sys.path = [fairing_code] + sys.path\n",
    "\n",
    "import fairing\n",
    "from fairing import cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PROJECT=code-search-demo\n",
      "DOCKER_REGISTRY=gcr.io/code-search-demo/fairing-job\n",
      "BASE_IMAGE=gcr.io/code-search-demo/mlapp/base:v20190410-ea12733-dirty-23b869\n"
     ]
    }
   ],
   "source": [
    "# Setting up google container repositories (GCR) for storing output containers\n",
    "# You can use any docker container registry istead of GCR\n",
    "GCP_PROJECT = cloud.gcp.guess_project_name()\n",
    "DOCKER_REGISTRY = 'gcr.io/{}/fairing-job'.format(GCP_PROJECT)\n",
    "BASE_IMAGE = \"gcr.io/code-search-demo/mlapp/base:v20190410-ea12733-dirty-23b869\"\n",
    "\n",
    "logging.info(\"PROJECT=%s\", GCP_PROJECT)\n",
    "logging.info(\"DOCKER_REGISTRY=%s\", DOCKER_REGISTRY)\n",
    "logging.info(\"BASE_IMAGE=%s\", BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy on Kubeflow\n",
    "\n",
    "Import the `fairing` library and configure the GCP environment that your training or prediction job will run in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using context dir /tmp/tmpru3rn1fh\n",
      "Using preprocessor: <fairing.preprocessors.base.BasePreProcessor object at 0x7f6154f5ef28>\n",
      "Using builder: <fairing.builders.append.append.AppendBuilder object at 0x7f6126d40320>\n",
      "Building image...\n",
      "Creating docker context: /tmp/fairing.context.tar.gz\n",
      "Adding files to context: {'mlapp.py', 'LabelPrediction.py', 'sql_models.py', 'utils.py', 'app.py', 'deploy_with_fairing.py'}\n",
      "Context: /tmp/fairing.context.tar.gz, Adding /home/jovyan/git_kubeflow-fairing/fairing/__init__.py at /app/fairing/__init__.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding /home/jovyan/git_kubeflow-fairing/fairing/runtime_config.py at /app/fairing/runtime_config.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding mlapp.py at /app/mlapp.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding LabelPrediction.py at /app/LabelPrediction.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding sql_models.py at /app/sql_models.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding utils.py at /app/utils.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding app.py at /app/app.py\n",
      "Context: /tmp/fairing.context.tar.gz, Adding deploy_with_fairing.py at /app/deploy_with_fairing.py\n",
      "Loading Docker credentials for repository 'gcr.io/code-search-demo/mlapp/base:v20190410-ea12733-dirty-23b869'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "Successfully obtained Docker credentials.\n",
      "Image successfully built in 0.7357582160038874s.\n",
      "Pushing image gcr.io/code-search-demo/fairing-job/fairing-job:BC9F0AF8...\n",
      "Loading Docker credentials for repository 'gcr.io/code-search-demo/fairing-job/fairing-job:BC9F0AF8'\n",
      "Invoking 'docker-credential-gcloud' to obtain Docker credentials.\n",
      "Successfully obtained Docker credentials.\n",
      "Uploading gcr.io/code-search-demo/fairing-job/fairing-job:BC9F0AF8\n",
      "Tag points to the right manifest, skipping push.\n",
      "Finished upload of: gcr.io/code-search-demo/fairing-job/fairing-job:BC9F0AF8\n",
      "Pushed image gcr.io/code-search-demo/fairing-job/fairing-job:BC9F0AF8 in 0.6784092430025339s.\n",
      "Deployment fairing-deployer-wvjzs launched.\n",
      "In cluster Endpoint http://fairing-service-qqghf.kubeflow.svc.cluster.local launched.\n"
     ]
    }
   ],
   "source": [
    "import deploy_with_fairing\n",
    "importlib.reload(deploy_with_fairing)\n",
    "_, _, deployer = deploy_with_fairing.deploy(DOCKER_REGISTRY, BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the prediction endpoint\n",
    "\n",
    "Create a test dataset, then call the endpoint on Kubeflow for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(url, data, feature_names=None):\n",
    "        pdata={\n",
    "            \"data\": {\n",
    "                \"names\":feature_names,\n",
    "                \"tensor\": {\n",
    "                    \"shape\": np.asarray(data.shape).tolist(),\n",
    "                    \"values\": data.flatten().tolist(),\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "        serialized_data = json.dumps(pdata)\n",
    "        r = requests.post(url, data={'json':serialized_data})\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b'{\"data\":{\"names\":[\"t:0\",\"t:1\",\"t:2\"],\"tensor\":{\"shape\":[1,3],\"values\":[0.948'\n",
      " b'5112428665161,0.04742114990949631,0.004067644942551851]}},\"meta\":{}}\\n')\n"
     ]
    }
   ],
   "source": [
    "# Note: first prediction is slow because we are loading the model.\n",
    "url = \"http://{0}.{1}.svc.cluster.local:5000/predict\".format(\n",
    "    deployer.service.metadata.name, deployer.service.metadata.namespace)\n",
    "    \n",
    "body = \"The cluster app is completely broken. Please fix it immediately.\"\n",
    "title = \"The cluster app is not working; please fix\"  \n",
    "r = predict(url, np.array([title, body]))\n",
    "pprint.pprint(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "!kubectl delete service -l app=mlapp\n",
    "!kubectl delete deploy -l app=mlapp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
